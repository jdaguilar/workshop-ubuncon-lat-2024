{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Workshop Image](static/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Workshop Ubucon Latinoamerica 2024\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el repositorio para el taller de Ubucon Latinoamerica 2024 titulado:\n",
    "\n",
    " Crea tu propio laboratorio de Big Data con MicroK8s y Spark\n",
    "\n",
    "A continuaci贸n se encuentra el enlace al video de la presentaci贸n [aqu铆](https://www.youtube.com/watch?v=kSlLjAXISA8):\n",
    "\n",
    "Recomendamos ver el video de la presentaci贸n antes de iniciar el taller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos\n",
    "\n",
    "**Disclaimer**: Este proyecto no ejecuta en Windows.\n",
    "\n",
    "Se recomienda correr el taller en una m谩quina con Ubuntu 22.04 o superior. Y adicionamente instalar el paquete de Snap. Para instalar Snap en tu m谩quina puedes seguir este enlace:\n",
    "[Instalar Snap](https://snapcraft.io/docs/installing-snapd)\n",
    "\n",
    "Para verificar que tienes instalado Snap en tu m谩quina puedes ejecutar el siguiente comando:\n",
    "```bash\n",
    "snap --version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar el proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ejecute el archivo `setup.sh` para desplegar los componentes de Kubernetes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "password = getpass.getpass()\n",
    "command = \"sudo -S bash setup.sh\" #can be any command but don't forget -S as it enables input from stdin\n",
    "os.system('echo %s | %s' % (password, command))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Ejecute el archivo `init_project.sh` para poder configurar los buckets de S3 en MinIO y configurar spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash init_project.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cargar c贸digos de prueba, con el script `upload_artifacts.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash upload_artifacts.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cargar c贸digos de prueba, con el script `upload_data.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash upload_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark-client.pyspark \\\n",
    "  --username spark \\\n",
    "  --namespace spark \\\n",
    "  --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-client.spark-submit \\\n",
    "    --username spark --namespace spark \\\n",
    "    --deploy-mode cluster \\\n",
    "    s3a://artifacts/python/count_vowels.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "pod_name=$(kubectl get pods -n spark | grep 'count-vowels-.*-driver' | tail -n 1 | cut -d' ' -f1)\n",
    "\n",
    "# View only the line containing the output\n",
    "kubectl logs $pod_name -n spark | grep \"The number of vowels in the string is\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-client.spark-submit \\\n",
    "    --username spark --namespace spark \\\n",
    "    --deploy-mode cluster \\\n",
    "    s3a://artifacts/python/process_gh_archive_data.py \\\n",
    "    --source_files_pattern=s3a://raw/gh_archive/year=2024/month=01/day=01/hour=0 \\\n",
    "    --destination_files_pattern=s3a://curated/parquet/gh_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-client.spark-submit \\\n",
    "    --username spark --namespace spark \\\n",
    "    --deploy-mode cluster \\\n",
    "    s3a://artifacts/python/process_gh_archive_data.py \\\n",
    "    --source_files_pattern=s3a://raw/gh_archive/year=2024/month=01/day=01/hour=1 \\\n",
    "    --destination_files_pattern=s3a://curated/parquet/gh_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-client.spark-submit \\\n",
    "    --username spark --namespace spark \\\n",
    "    --deploy-mode cluster \\\n",
    "    --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.0 \\\n",
    "    s3a://artifacts/python/demo_iceberg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-client.spark-submit \\\n",
    "    --username spark --namespace spark \\\n",
    "    --deploy-mode cluster \\\n",
    "    s3a://artifacts/python/process_gh_archive_data_iceberg.py \\\n",
    "    --source_files_pattern=s3a://raw/gh_archive/year=2024/month=01/day=02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-client.spark-submit \\\n",
    "    --username spark --namespace spark \\\n",
    "    --deploy-mode cluster \\\n",
    "    --packages org.apache.hudi:hudi-spark3.4-bundle_2.12:0.15.0  \\\n",
    "    s3a://artifacts/python/process_gh_archive_data_hudi.py  \\\n",
    "    --source_files_pattern=s3a://raw/gh_archive/year=2024/month=01/day=02/hour=0\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
